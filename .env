# Doclin
DOC_MODEL_NAME= 'sentence-transformers/all-MiniLM-L6-v2'
DOC_COLLECTION_NAME= 'excel_data'

# Chromadb
CHR_DIRECTORY = './chromadb_data'

# Milvus Configuration
USE_LOCAL=False
LOCAL_MILVUS_URI=LOCAL_MILVUS_URI
MILVUS_URI=MILVUS_URI
MILVUS_USER=MILVUS_USER
MILVUS_PASSWORD=MILVUS_PASSWORD
VECTOR_DIMENSION=1536
# ---------- Paths ----------
# Folder or single file. If you don't pass --path, this is used.
DOC_BASE_PATH=DOC_BASE_PATH
# Default extension filter if you don't pass --ext
DOC_EXTENSION=pdf
# ---------- Collection ----------
COLLECTION_NAME_1=COLLECTION_NAME_1

# ---------- Embeddings & Index ----------
EMBED_MODEL=EMBED_MODEL
METRIC_TYPE=L2          # use COSINE if your model was trained with cosine
INDEX_TYPE=IVF_FLAT
INDEX_NLIST=128

# ---------- Chunking ----------
CHUNK_MAX_TOKENS=500
CHUNK_MIN_TOKENS=120
CHUNK_OVERLAP=50
# (leave CHUNK_MIN_TOKENS as-is, or set e.g. 200)


# OpenAI Configuration
OPENAI_API_KEY=OPENAI_API_KEY
OPENAI_API_KEY1=OPENAI_API_KEY1
OPENAI_MODEL= OPENAI_MODEL #gpt-3.5-turbo

# MISTRAIL Configuration
MISTRAL_API_KEY=MISTRAL_API_KEY
MISTRAL_EMBEDDING_MODEL=MISTRAL_EMBEDDING_MODEL
MISTRAIL_LLM_MODEL=MISTRAIL_LLM_MODEL

# Huggingface embeding models Configuration
HUG_MODEL_NAME = "BAAI/bge-large-en"
HUG_MODEL_KWARGS = {'device': 'cpu'}
HUG_MODEL_ENCODE_KWARGS = {'normalize_embeddings': False}
HUG_TOKEN = HUG_TOKEN
# qdrant
QDRANT_URL = QDRANT_URL

# Deepseek
DEEP_API_KEY=DEEP_API_KEY

# GROQ
GROQ_API_KEY= GROQ_API_KEY
GROQ_EMBEDING_MODEL= GROQ_EMBEDING_MODEL
GROQ_LLM_MODEL= GROQ_LLM_MODEL





