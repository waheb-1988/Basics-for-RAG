# Doclin
DOC_MODEL_NAME= 'sentence-transformers/all-MiniLM-L6-v2'
DOC_COLLECTION_NAME= 'excel_data'

# Chromadb
CHR_DIRECTORY = './chromadb_data'

# Milvus Configuration
USE_LOCAL=False
LOCAL_MILVUS_URI=tcp://localhost:19530
MILVUS_URI=https://in03-3aca0c0555292d6.serverless.gcp-us-west1.cloud.zilliz.com
MILVUS_USER=db_3aca0c0555292d6
MILVUS_PASSWORD=Lv2&85uT<|/hxU;O
VECTOR_DIMENSION=1536
# ---------- Paths ----------
# Folder or single file. If you don't pass --path, this is used.
DOC_BASE_PATH=C:\Abdelouaheb\perso\Data_science_2024_projects\2025\Basics-for-RAG\data\pdf
# Default extension filter if you don't pass --ext
DOC_EXTENSION=pdf
# ---------- Collection ----------
COLLECTION_NAME_1=docling_vectors_pdf

# ---------- Embeddings & Index ----------
EMBED_MODEL=sangmini/msmarco-cotmae-MiniLM-L12_en-ko-ja
METRIC_TYPE=L2          # use COSINE if your model was trained with cosine
INDEX_TYPE=IVF_FLAT
INDEX_NLIST=128

# ---------- Chunking ----------
CHUNK_MAX_TOKENS=500
CHUNK_MIN_TOKENS=120
CHUNK_OVERLAP=50
# (leave CHUNK_MIN_TOKENS as-is, or set e.g. 200)


# OpenAI Configuration
OPENAI_API_KEY=OPENAI_API_KEY
OPENAI_API_KEY1=OPENAI_API_KEY1
OPENAI_MODEL= OPENAI_MODEL #gpt-3.5-turbo

# MISTRAIL Configuration
MISTRAL_API_KEY=MISTRAL_API_KEY
MISTRAL_EMBEDDING_MODEL=MISTRAL_EMBEDDING_MODEL
MISTRAIL_LLM_MODEL="mistral-large-MISTRAIL_LLM_MODEL"

# Huggingface embeding models Configuration
HUG_MODEL_NAME = "BAAI/bge-large-en"
HUG_MODEL_KWARGS = {'device': 'cpu'}
HUG_MODEL_ENCODE_KWARGS = {'normalize_embeddings': False}
HUG_TOKEN = HUG_TOKEN
# qdrant
QDRANT_URL = QDRANT_URL

# Deepseek
DEEP_API_KEY=DEEP_API_KEY

# GROQ
GROQ_API_KEY= GROQ_API_KEY
GROQ_EMBEDING_MODEL= GROQ_EMBEDING_MODEL
GROQ_LLM_MODEL= GROQ_LLM_MODEL





